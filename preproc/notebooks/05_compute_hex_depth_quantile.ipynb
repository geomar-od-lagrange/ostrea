{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Compute per-hex depth quantile from GEBCO\n",
    "\n",
    "Replaces the mean/median depth in `meta.json` with a low quantile (10th percentile)\n",
    "of GEBCO 2022 bathymetry sampled within each hex polygon.\n",
    "\n",
    "**Why:** mean/median depth misclassifies hexes near steep coasts (e.g. Norway) as\n",
    "non-habitable even when a substantial fraction of their area is shallower than 85 m.\n",
    "\n",
    "**Source:** GEBCO_2022 sub-ice topography/bathymetry via CEDA OPeNDAP (~450 m resolution).\n",
    "CEDA login may be required — see https://services.ceda.ac.uk/cedasite/register/info/\n",
    "\n",
    "**Output:** updated `database/data/meta.json` with `depth` replaced by the 10th percentile\n",
    "of ocean depth within each hex (land points and dry cells excluded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- parameters ---\n",
    "DEPTH_QUANTILE = 0.10   # 10th percentile\n",
    "\n",
    "# GEBCO 2022 via CEDA OPeNDAP\n",
    "# Note: CEDA requires free registration; set CEDA credentials in ~/.dodsrc if needed\n",
    "GEBCO_URL = (\n",
    "    \"https://dap.ceda.ac.uk/bodc/gebco/global/gebco_2022\"\n",
    "    \"/sub_ice_topography_bathymetry/netcdf/GEBCO_2022_sub_ice_topo.nc\"\n",
    ")\n",
    "\n",
    "# Study region bounding box (NW European shelf, with margin)\n",
    "LON_MIN, LON_MAX = -30.0, 15.0\n",
    "LAT_MIN, LAT_MAX =  45.0, 65.0\n",
    "\n",
    "OUT_DIR = Path(\"../../database/data\")\n",
    "META_PATH = OUT_DIR / \"meta.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GEBCO for the study region via OPeNDAP (downloads once, ~100 MB subset)\n",
    "print(\"Opening GEBCO via OPeNDAP ...\")\n",
    "ds = xr.open_dataset(GEBCO_URL, engine=\"pydap\")\n",
    "print(ds)\n",
    "\n",
    "print(\"\\nSubsetting to study region ...\")\n",
    "elev = (\n",
    "    ds[\"elevation\"]\n",
    "    .sel(lat=slice(LAT_MIN, LAT_MAX), lon=slice(LON_MIN, LON_MAX))\n",
    "    .load()   # pull into memory once\n",
    ")\n",
    "print(f\"Loaded: {elev.shape} (lat × lon), {elev.nbytes / 1e6:.0f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check: depth should be negative elevation for ocean cells\n",
    "ocean_frac = float((elev < 0).sum() / elev.size)\n",
    "print(f\"Ocean fraction in study region: {ocean_frac:.1%}\")\n",
    "print(f\"Elevation range: {float(elev.min()):.0f} m to {float(elev.max()):.0f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hex polygons\n",
    "hexes = gpd.read_file(OUT_DIR / \"hexes.geojson\")\n",
    "print(f\"Hexes: {len(hexes)}\")\n",
    "hexes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-extract coordinate arrays for fast bbox slicing\n",
    "lons = elev.lon.values\n",
    "lats = elev.lat.values\n",
    "\n",
    "def hex_depth_quantile(geom, q=DEPTH_QUANTILE):\n",
    "    \"\"\"Return q-th quantile of ocean depth (m, positive) within hex polygon.\"\"\"\n",
    "    minx, miny, maxx, maxy = geom.bounds\n",
    "\n",
    "    # Slice GEBCO to hex bounding box (+ tiny margin)\n",
    "    local = elev.sel(\n",
    "        lat=slice(miny - 0.01, maxy + 0.01),\n",
    "        lon=slice(minx - 0.01, maxx + 0.01),\n",
    "    )\n",
    "    if local.size == 0:\n",
    "        return np.nan\n",
    "\n",
    "    local_lons = local.lon.values\n",
    "    local_lats = local.lat.values\n",
    "    LON_G, LAT_G = np.meshgrid(local_lons, local_lats)\n",
    "\n",
    "    # Mask to polygon using shapely 2.x vectorised contains\n",
    "    inside = shapely.contains_xy(geom, LON_G.ravel(), LAT_G.ravel())\n",
    "    elev_vals = local.values.ravel()[inside]\n",
    "\n",
    "    # Ocean only: GEBCO elevation < 0 → depth = -elevation\n",
    "    ocean_depths = -elev_vals[elev_vals < 0]\n",
    "    if len(ocean_depths) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    return float(np.percentile(ocean_depths, q * 100))\n",
    "\n",
    "print(\"Function defined. Test on first hex:\")\n",
    "print(hex_depth_quantile(hexes.geometry.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-hex depth quantile for all hexes\n",
    "depth_q = np.full(len(hexes), np.nan)\n",
    "\n",
    "for i, geom in enumerate(tqdm(hexes.geometry, desc=\"hex depth q10\")):\n",
    "    depth_q[i] = hex_depth_quantile(geom)\n",
    "\n",
    "hexes[\"depth_q10\"] = depth_q\n",
    "print(f\"Done. NaN count: {np.isnan(depth_q).sum()} / {len(depth_q)}\")\n",
    "print(f\"Depth q10 range: {np.nanmin(depth_q):.0f} – {np.nanmax(depth_q):.0f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare old median depth vs new q10 depth for hexes near Norway\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "meta = json.loads(META_PATH.read_text())\n",
    "old_depth = np.array([meta[\"depth\"].get(str(i), np.nan) for i in hexes[\"id\"]])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for ax, vals, title in zip(\n",
    "    axes,\n",
    "    [old_depth, depth_q],\n",
    "    [\"Old: depth_median (from NetCDF)\", f\"New: depth_q{int(DEPTH_QUANTILE*100)} (GEBCO)\"],\n",
    "):\n",
    "    sc = ax.scatter(hexes.geometry.centroid.x, hexes.geometry.centroid.y,\n",
    "                    c=vals, cmap=\"Blues\", vmin=0, vmax=200, s=2)\n",
    "    ax.set_title(title)\n",
    "    plt.colorbar(sc, ax=ax, label=\"depth (m)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"depth_comparison.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how many hexes change habitable status (depth > 85 m threshold)\n",
    "was_nonhabitable = old_depth > 85\n",
    "now_nonhabitable = depth_q > 85\n",
    "newly_habitable = was_nonhabitable & ~now_nonhabitable\n",
    "print(f\"Previously non-habitable (depth_median > 85 m): {was_nonhabitable.sum()}\")\n",
    "print(f\"Now non-habitable (depth_q10 > 85 m):           {now_nonhabitable.sum()}\")\n",
    "print(f\"Newly classified as habitable:                   {newly_habitable.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write updated meta.json: replace 'depth' with depth_q10\n",
    "# NaN → None so JSON serialises cleanly\n",
    "new_depth = {\n",
    "    str(int(row[\"id\"])): (None if np.isnan(row[\"depth_q10\"]) else row[\"depth_q10\"])\n",
    "    for _, row in hexes.iterrows()\n",
    "}\n",
    "meta[\"depth\"] = new_depth\n",
    "\n",
    "META_PATH.write_text(json.dumps(meta))\n",
    "print(f\"Written: {META_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
