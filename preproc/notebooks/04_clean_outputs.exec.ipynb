{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1000001",
   "metadata": {
    "papermill": {
     "duration": 0.002693,
     "end_time": "2026-02-27T23:33:46.109011",
     "exception": false,
     "start_time": "2026-02-27T23:33:46.106318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Clean outputs\n",
    "\n",
    "Post-processing step after notebooks 02 and 03.\n",
    "\n",
    "Removes features with NaN corner coordinates from `hexes.geojson`\n",
    "and drops orphan rows referencing those hex IDs from all connectivity parquets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1000002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T23:33:46.113648Z",
     "iopub.status.busy": "2026-02-27T23:33:46.113396Z",
     "iopub.status.idle": "2026-02-27T23:33:46.320513Z",
     "shell.execute_reply": "2026-02-27T23:33:46.320051Z"
    },
    "papermill": {
     "duration": 0.210128,
     "end_time": "2026-02-27T23:33:46.321061",
     "exception": false,
     "start_time": "2026-02-27T23:33:46.110933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT_DIR: /Users/wrath/src/github.com/geomar-od-lagrange/ostrea/database/data\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "_cwd = Path.cwd()\n",
    "if (_cwd / \"../database/data\").exists():\n",
    "    OUT_DIR = (_cwd / \"../database/data\").resolve()\n",
    "else:\n",
    "    OUT_DIR = (_cwd / \"../../database/data\").resolve()\n",
    "print(f\"OUT_DIR: {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1000003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T23:33:46.322954Z",
     "iopub.status.busy": "2026-02-27T23:33:46.322834Z",
     "iopub.status.idle": "2026-02-27T23:33:46.357253Z",
     "shell.execute_reply": "2026-02-27T23:33:46.356687Z"
    },
    "papermill": {
     "duration": 0.03591,
     "end_time": "2026-02-27T23:33:46.357751",
     "exception": false,
     "start_time": "2026-02-27T23:33:46.321841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hex IDs with NaN/Inf corners: [] (0 total)\n"
     ]
    }
   ],
   "source": [
    "# Find hex IDs with NaN or Inf corner coordinates\n",
    "with open(OUT_DIR / \"hexes.geojson\") as f:\n",
    "    gj = json.load(f)\n",
    "\n",
    "bad_ids = set()\n",
    "for feat in gj[\"features\"]:\n",
    "    coords = feat[\"geometry\"][\"coordinates\"][0]\n",
    "    if any(not math.isfinite(v) for pt in coords for v in pt):\n",
    "        bad_ids.add(feat[\"properties\"][\"id\"])\n",
    "\n",
    "print(f\"Hex IDs with NaN/Inf corners: {sorted(bad_ids)} ({len(bad_ids)} total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1000004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T23:33:46.359506Z",
     "iopub.status.busy": "2026-02-27T23:33:46.359419Z",
     "iopub.status.idle": "2026-02-27T23:33:46.517329Z",
     "shell.execute_reply": "2026-02-27T23:33:46.517008Z"
    },
    "papermill": {
     "duration": 0.159512,
     "end_time": "2026-02-27T23:33:46.517958",
     "exception": false,
     "start_time": "2026-02-27T23:33:46.358446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexes.geojson: 8414 -> 8414 features\n",
      "meta.json: no bad IDs, unchanged (8425 entries)\n"
     ]
    }
   ],
   "source": [
    "# Drop bad features from hexes.geojson and meta.json\n",
    "before = len(gj[\"features\"])\n",
    "gj[\"features\"] = [f for f in gj[\"features\"] if f[\"properties\"][\"id\"] not in bad_ids]\n",
    "with open(OUT_DIR / \"hexes.geojson\", \"w\") as f:\n",
    "    json.dump(gj, f)\n",
    "print(f\"hexes.geojson: {before} -> {len(gj['features'])} features\")\n",
    "\n",
    "# meta.json is columnar: {\"id\": {\"0\": 0, ...}, \"lon\": {...}, ...}\n",
    "with open(OUT_DIR / \"meta.json\") as f:\n",
    "    meta = json.load(f)\n",
    "if bad_ids:\n",
    "    ids_col = meta[\"id\"]  # {\"0\": 0, \"1\": 1, ...}\n",
    "    bad_row_keys = {k for k, v in ids_col.items() if v in bad_ids}\n",
    "    before_meta = len(ids_col)\n",
    "    meta = {col: {k: v for k, v in col_data.items() if k not in bad_row_keys}\n",
    "            for col, col_data in meta.items()}\n",
    "    with open(OUT_DIR / \"meta.json\", \"w\") as f:\n",
    "        json.dump(meta, f)\n",
    "    print(f\"meta.json: {before_meta} -> {len(meta['id'])} entries\")\n",
    "else:\n",
    "    print(f\"meta.json: no bad IDs, unchanged ({len(meta['id'])} entries)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1000005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T23:33:46.519847Z",
     "iopub.status.busy": "2026-02-27T23:33:46.519738Z",
     "iopub.status.idle": "2026-02-27T23:33:51.353256Z",
     "shell.execute_reply": "2026-02-27T23:33:51.352726Z"
    },
    "papermill": {
     "duration": 4.835153,
     "end_time": "2026-02-27T23:33:51.353856",
     "exception": false,
     "start_time": "2026-02-27T23:33:46.518703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_05m_00d-07d.pq: dropped 0 orphans, 0 zero-weight rows, 1,028,478 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_05m_07d-14d.pq: dropped 0 orphans, 0 zero-weight rows, 1,892,431 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_05m_07d-28d.pq: dropped 0 orphans, 0 zero-weight rows, 3,407,838 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_10m_00d-07d.pq: dropped 0 orphans, 0 zero-weight rows, 1,015,297 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_10m_07d-14d.pq: dropped 0 orphans, 0 zero-weight rows, 1,864,143 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_10m_07d-28d.pq: dropped 0 orphans, 0 zero-weight rows, 3,320,873 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_15m_00d-07d.pq: dropped 0 orphans, 0 zero-weight rows, 967,342 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_15m_07d-14d.pq: dropped 0 orphans, 0 zero-weight rows, 1,802,339 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_15m_07d-28d.pq: dropped 0 orphans, 0 zero-weight rows, 3,215,520 remaining\n"
     ]
    }
   ],
   "source": [
    "# Drop orphan rows from all connectivity parquets, round weights to 3 sig figs, and drop zero-weight rows\n",
    "for path in sorted(OUT_DIR.glob(\"connectivity_*.pq\")):\n",
    "    df = pd.read_parquet(path)\n",
    "    mask = df[\"end_id\"].astype(int).isin(bad_ids) | df[\"start_id\"].isin(bad_ids)\n",
    "    dropped = mask.sum()\n",
    "    df = df[~mask].copy()\n",
    "    w = df[\"weight\"].values\n",
    "    exp = np.floor(np.log10(w))\n",
    "    df[\"weight\"] = np.round(w * 10 ** (2 - exp)) / 10 ** (2 - exp)\n",
    "    before_zero = len(df)\n",
    "    df = df[df[\"weight\"] > 0]\n",
    "    dropped_zero = before_zero - len(df)\n",
    "    df.to_parquet(path, index=False)\n",
    "    print(f\"{path.name}: dropped {dropped} orphans, {dropped_zero} zero-weight rows, {len(df):,} remaining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kr05uztc5f",
   "metadata": {
    "papermill": {
     "duration": 0.000724,
     "end_time": "2026-02-27T23:33:51.355687",
     "exception": false,
     "start_time": "2026-02-27T23:33:51.354963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prune small disconnected hex clusters\n",
    "\n",
    "Uses cube-coordinate adjacency to find connected components of the hex grid.\n",
    "Components with â‰¤ 3 hexes are removed from all data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cetajcvh1fj",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T23:33:51.357695Z",
     "iopub.status.busy": "2026-02-27T23:33:51.357589Z",
     "iopub.status.idle": "2026-02-27T23:33:51.384057Z",
     "shell.execute_reply": "2026-02-27T23:33:51.383639Z"
    },
    "papermill": {
     "duration": 0.028236,
     "end_time": "2026-02-27T23:33:51.384590",
     "exception": false,
     "start_time": "2026-02-27T23:33:51.356354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total components: 4\n",
      "Size distribution (size: count):\n",
      "     1 hex:    2 component(s)\n",
      "     3 hex:    1 component(s)\n",
      "  8420 hex:    1 component(s)\n",
      "\n",
      "Hex IDs to prune (cluster size < 4): 5\n"
     ]
    }
   ],
   "source": [
    "MIN_CLUSTER_SIZE = 4   # remove components with fewer than this many hexes\n",
    "\n",
    "# Parse cube coordinates from hex label strings like \"(-1, -19, 20)\"\n",
    "with open(OUT_DIR / \"hex_label_to_id.json\") as f:\n",
    "    label_to_id = json.load(f)\n",
    "\n",
    "def parse_cube(label: str):\n",
    "    return tuple(int(x) for x in label.strip(\"()\").split(\",\"))\n",
    "\n",
    "cubes = {parse_cube(lbl): int(hex_id) for lbl, hex_id in label_to_id.items()}\n",
    "cube_set = set(cubes)\n",
    "\n",
    "# Six cube-coordinate neighbor directions\n",
    "DIRECTIONS = [(1,-1,0),(-1,1,0),(1,0,-1),(-1,0,1),(0,1,-1),(0,-1,1)]\n",
    "\n",
    "# BFS connected components\n",
    "visited = set()\n",
    "components = []   # list of sets of int IDs\n",
    "\n",
    "for cube in cube_set:\n",
    "    if cube in visited:\n",
    "        continue\n",
    "    component = set()\n",
    "    queue = [cube]\n",
    "    while queue:\n",
    "        c = queue.pop()\n",
    "        if c in visited:\n",
    "            continue\n",
    "        visited.add(c)\n",
    "        component.add(cubes[c])\n",
    "        for d in DIRECTIONS:\n",
    "            nb = (c[0]+d[0], c[1]+d[1], c[2]+d[2])\n",
    "            if nb in cube_set and nb not in visited:\n",
    "                queue.append(nb)\n",
    "    components.append(component)\n",
    "\n",
    "components.sort(key=len)\n",
    "print(f\"Total components: {len(components)}\")\n",
    "print(f\"Size distribution (size: count):\")\n",
    "from collections import Counter\n",
    "size_counts = Counter(len(c) for c in components)\n",
    "for size in sorted(size_counts):\n",
    "    print(f\"  {size:4d} hex: {size_counts[size]:4d} component(s)\")\n",
    "\n",
    "small_ids = set().union(*(c for c in components if len(c) < MIN_CLUSTER_SIZE))\n",
    "print(f\"\\nHex IDs to prune (cluster size < {MIN_CLUSTER_SIZE}): {len(small_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wy53wuz9dol",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T23:33:51.386754Z",
     "iopub.status.busy": "2026-02-27T23:33:51.386658Z",
     "iopub.status.idle": "2026-02-27T23:33:55.568592Z",
     "shell.execute_reply": "2026-02-27T23:33:55.568106Z"
    },
    "papermill": {
     "duration": 4.183621,
     "end_time": "2026-02-27T23:33:55.569076",
     "exception": false,
     "start_time": "2026-02-27T23:33:51.385455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexes.geojson: 8414 -> 8410 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta.json: 8425 -> 8420 entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_05m_00d-07d.pq: 1,028,478 -> 1,028,478 rows (0 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_05m_07d-14d.pq: 1,892,431 -> 1,892,431 rows (0 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_05m_07d-28d.pq: 3,407,838 -> 3,407,838 rows (0 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_10m_00d-07d.pq: 1,015,297 -> 1,015,297 rows (0 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_10m_07d-14d.pq: 1,864,143 -> 1,864,143 rows (0 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_10m_07d-28d.pq: 3,320,873 -> 3,320,873 rows (0 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_15m_00d-07d.pq: 967,342 -> 967,338 rows (4 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_15m_07d-14d.pq: 1,802,339 -> 1,802,334 rows (5 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_15m_07d-28d.pq: 3,215,520 -> 3,215,515 rows (5 dropped)\n"
     ]
    }
   ],
   "source": [
    "# Remove small-cluster hexes from hexes.geojson, meta.json, and parquets\n",
    "with open(OUT_DIR / \"hexes.geojson\") as f:\n",
    "    gj = json.load(f)\n",
    "before = len(gj[\"features\"])\n",
    "gj[\"features\"] = [f for f in gj[\"features\"] if f[\"properties\"][\"id\"] not in small_ids]\n",
    "with open(OUT_DIR / \"hexes.geojson\", \"w\") as f:\n",
    "    json.dump(gj, f)\n",
    "print(f\"hexes.geojson: {before} -> {len(gj['features'])} features\")\n",
    "\n",
    "with open(OUT_DIR / \"meta.json\") as f:\n",
    "    meta = json.load(f)\n",
    "ids_col = meta[\"id\"]\n",
    "bad_row_keys = {k for k, v in ids_col.items() if v in small_ids}\n",
    "before_meta = len(ids_col)\n",
    "meta = {col: {k: v for k, v in col_data.items() if k not in bad_row_keys}\n",
    "        for col, col_data in meta.items()}\n",
    "with open(OUT_DIR / \"meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f)\n",
    "print(f\"meta.json: {before_meta} -> {len(meta['id'])} entries\")\n",
    "\n",
    "for path in sorted(OUT_DIR.glob(\"connectivity_*.pq\")):\n",
    "    df = pd.read_parquet(path)\n",
    "    before_pq = len(df)\n",
    "    mask = df[\"end_id\"].astype(int).isin(small_ids) | df[\"start_id\"].isin(small_ids)\n",
    "    df = df[~mask]\n",
    "    df.to_parquet(path, index=False)\n",
    "    print(f\"{path.name}: {before_pq:,} -> {len(df):,} rows ({mask.sum()} dropped)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.269694,
   "end_time": "2026-02-27T23:33:55.786394",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/04_clean_outputs.ipynb",
   "output_path": "notebooks/04_clean_outputs.exec.ipynb",
   "parameters": {},
   "start_time": "2026-02-27T23:33:45.516700",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}