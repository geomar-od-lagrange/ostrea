{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1000001",
   "metadata": {
    "papermill": {
     "duration": 0.006576,
     "end_time": "2026-02-28T09:42:59.666868",
     "exception": false,
     "start_time": "2026-02-28T09:42:59.660292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Clean outputs\n",
    "\n",
    "Post-processing step after notebooks 02 and 03.\n",
    "\n",
    "Removes features with NaN corner coordinates from `hexes.geojson`\n",
    "and drops orphan rows referencing those hex IDs from all connectivity parquets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1000002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T09:42:59.675231Z",
     "iopub.status.busy": "2026-02-28T09:42:59.674832Z",
     "iopub.status.idle": "2026-02-28T09:43:00.015468Z",
     "shell.execute_reply": "2026-02-28T09:43:00.014858Z"
    },
    "papermill": {
     "duration": 0.345268,
     "end_time": "2026-02-28T09:43:00.015960",
     "exception": false,
     "start_time": "2026-02-28T09:42:59.670692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT_DIR: /Users/wrath/src/github.com/geomar-od-lagrange/ostrea/database/data\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "_cwd = Path.cwd()\n",
    "if (_cwd / \"../database/data\").exists():\n",
    "    OUT_DIR = (_cwd / \"../database/data\").resolve()\n",
    "else:\n",
    "    OUT_DIR = (_cwd / \"../../database/data\").resolve()\n",
    "print(f\"OUT_DIR: {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1000003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T09:43:00.018226Z",
     "iopub.status.busy": "2026-02-28T09:43:00.018061Z",
     "iopub.status.idle": "2026-02-28T09:43:00.055029Z",
     "shell.execute_reply": "2026-02-28T09:43:00.054593Z"
    },
    "papermill": {
     "duration": 0.038752,
     "end_time": "2026-02-28T09:43:00.055721",
     "exception": false,
     "start_time": "2026-02-28T09:43:00.016969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hex IDs with NaN/Inf corners: [] (0 total)\n"
     ]
    }
   ],
   "source": [
    "# Find hex IDs with NaN or Inf corner coordinates\n",
    "with open(OUT_DIR / \"hexes.geojson\") as f:\n",
    "    gj = json.load(f)\n",
    "\n",
    "bad_ids = set()\n",
    "for feat in gj[\"features\"]:\n",
    "    coords = feat[\"geometry\"][\"coordinates\"][0]\n",
    "    if any(not math.isfinite(v) for pt in coords for v in pt):\n",
    "        bad_ids.add(feat[\"properties\"][\"id\"])\n",
    "\n",
    "print(f\"Hex IDs with NaN/Inf corners: {sorted(bad_ids)} ({len(bad_ids)} total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1000004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T09:43:00.057972Z",
     "iopub.status.busy": "2026-02-28T09:43:00.057847Z",
     "iopub.status.idle": "2026-02-28T09:43:00.226899Z",
     "shell.execute_reply": "2026-02-28T09:43:00.226490Z"
    },
    "papermill": {
     "duration": 0.170705,
     "end_time": "2026-02-28T09:43:00.227368",
     "exception": false,
     "start_time": "2026-02-28T09:43:00.056663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexes.geojson: 8410 -> 8410 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta.json: no bad IDs, unchanged (8420 entries)\n"
     ]
    }
   ],
   "source": [
    "# Drop bad features from hexes.geojson and meta.json\n",
    "before = len(gj[\"features\"])\n",
    "gj[\"features\"] = [f for f in gj[\"features\"] if f[\"properties\"][\"id\"] not in bad_ids]\n",
    "with open(OUT_DIR / \"hexes.geojson\", \"w\") as f:\n",
    "    json.dump(gj, f)\n",
    "print(f\"hexes.geojson: {before} -> {len(gj['features'])} features\")\n",
    "\n",
    "# meta.json is columnar: {\"id\": {\"0\": 0, ...}, \"lon\": {...}, ...}\n",
    "with open(OUT_DIR / \"meta.json\") as f:\n",
    "    meta = json.load(f)\n",
    "if bad_ids:\n",
    "    ids_col = meta[\"id\"]  # {\"0\": 0, \"1\": 1, ...}\n",
    "    bad_row_keys = {k for k, v in ids_col.items() if v in bad_ids}\n",
    "    before_meta = len(ids_col)\n",
    "    meta = {col: {k: v for k, v in col_data.items() if k not in bad_row_keys}\n",
    "            for col, col_data in meta.items()}\n",
    "    with open(OUT_DIR / \"meta.json\", \"w\") as f:\n",
    "        json.dump(meta, f)\n",
    "    print(f\"meta.json: {before_meta} -> {len(meta['id'])} entries\")\n",
    "else:\n",
    "    print(f\"meta.json: no bad IDs, unchanged ({len(meta['id'])} entries)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1000005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T09:43:00.229350Z",
     "iopub.status.busy": "2026-02-28T09:43:00.229246Z",
     "iopub.status.idle": "2026-02-28T09:43:05.170631Z",
     "shell.execute_reply": "2026-02-28T09:43:05.170177Z"
    },
    "papermill": {
     "duration": 4.942978,
     "end_time": "2026-02-28T09:43:05.171198",
     "exception": false,
     "start_time": "2026-02-28T09:43:00.228220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_05m_00d-07d.pq: dropped 0 orphans, 0 zero-weight rows, 1,028,496 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_05m_07d-14d.pq: dropped 0 orphans, 0 zero-weight rows, 1,892,431 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_05m_07d-28d.pq: dropped 0 orphans, 0 zero-weight rows, 3,407,859 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_10m_00d-07d.pq: dropped 0 orphans, 1564 zero-weight rows, 1,015,297 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_10m_07d-14d.pq: dropped 0 orphans, 2347 zero-weight rows, 1,861,171 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_10m_07d-28d.pq: dropped 0 orphans, 3348 zero-weight rows, 3,320,873 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_15m_00d-07d.pq: dropped 0 orphans, 1540 zero-weight rows, 985,539 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_15m_07d-14d.pq: dropped 0 orphans, 2308 zero-weight rows, 1,803,563 remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_15m_07d-28d.pq: dropped 0 orphans, 3268 zero-weight rows, 3,215,520 remaining\n"
     ]
    }
   ],
   "source": [
    "# Drop orphan rows from all connectivity parquets, round weights to 3 sig figs, and drop zero-weight rows\n",
    "for path in sorted(OUT_DIR.glob(\"connectivity_*.pq\")):\n",
    "    df = pd.read_parquet(path)\n",
    "    mask = df[\"end_id\"].astype(int).isin(bad_ids) | df[\"start_id\"].isin(bad_ids)\n",
    "    dropped = mask.sum()\n",
    "    df = df[~mask].copy()\n",
    "    w = df[\"weight\"].values\n",
    "    exp = np.floor(np.log10(w))\n",
    "    df[\"weight\"] = np.round(w * 10 ** (2 - exp)) / 10 ** (2 - exp)\n",
    "    before_zero = len(df)\n",
    "    df = df[df[\"weight\"] > 0]\n",
    "    dropped_zero = before_zero - len(df)\n",
    "    df.to_parquet(path, index=False)\n",
    "    print(f\"{path.name}: dropped {dropped} orphans, {dropped_zero} zero-weight rows, {len(df):,} remaining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kr05uztc5f",
   "metadata": {
    "papermill": {
     "duration": 0.00073,
     "end_time": "2026-02-28T09:43:05.172870",
     "exception": false,
     "start_time": "2026-02-28T09:43:05.172140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prune small disconnected hex clusters\n",
    "\n",
    "Uses cube-coordinate adjacency to find connected components of the hex grid.\n",
    "Components with â‰¤ 3 hexes are removed from all data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cetajcvh1fj",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T09:43:05.174859Z",
     "iopub.status.busy": "2026-02-28T09:43:05.174765Z",
     "iopub.status.idle": "2026-02-28T09:43:05.199193Z",
     "shell.execute_reply": "2026-02-28T09:43:05.198807Z"
    },
    "papermill": {
     "duration": 0.02608,
     "end_time": "2026-02-28T09:43:05.199660",
     "exception": false,
     "start_time": "2026-02-28T09:43:05.173580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total components: 4\n",
      "Size distribution (size: count):\n",
      "     1 hex:    2 component(s)\n",
      "     3 hex:    1 component(s)\n",
      "  8420 hex:    1 component(s)\n",
      "\n",
      "Hex IDs to prune (cluster size < 4): 5\n"
     ]
    }
   ],
   "source": [
    "MIN_CLUSTER_SIZE = 4   # remove components with fewer than this many hexes\n",
    "\n",
    "# Parse cube coordinates from hex label strings like \"(-1, -19, 20)\"\n",
    "with open(OUT_DIR / \"hex_label_to_id.json\") as f:\n",
    "    label_to_id = json.load(f)\n",
    "\n",
    "def parse_cube(label: str):\n",
    "    return tuple(int(x) for x in label.strip(\"()\").split(\",\"))\n",
    "\n",
    "cubes = {parse_cube(lbl): int(hex_id) for lbl, hex_id in label_to_id.items()}\n",
    "cube_set = set(cubes)\n",
    "\n",
    "# Six cube-coordinate neighbor directions\n",
    "DIRECTIONS = [(1,-1,0),(-1,1,0),(1,0,-1),(-1,0,1),(0,1,-1),(0,-1,1)]\n",
    "\n",
    "# BFS connected components\n",
    "visited = set()\n",
    "components = []   # list of sets of int IDs\n",
    "\n",
    "for cube in cube_set:\n",
    "    if cube in visited:\n",
    "        continue\n",
    "    component = set()\n",
    "    queue = [cube]\n",
    "    while queue:\n",
    "        c = queue.pop()\n",
    "        if c in visited:\n",
    "            continue\n",
    "        visited.add(c)\n",
    "        component.add(cubes[c])\n",
    "        for d in DIRECTIONS:\n",
    "            nb = (c[0]+d[0], c[1]+d[1], c[2]+d[2])\n",
    "            if nb in cube_set and nb not in visited:\n",
    "                queue.append(nb)\n",
    "    components.append(component)\n",
    "\n",
    "components.sort(key=len)\n",
    "print(f\"Total components: {len(components)}\")\n",
    "print(f\"Size distribution (size: count):\")\n",
    "from collections import Counter\n",
    "size_counts = Counter(len(c) for c in components)\n",
    "for size in sorted(size_counts):\n",
    "    print(f\"  {size:4d} hex: {size_counts[size]:4d} component(s)\")\n",
    "\n",
    "small_ids = set().union(*(c for c in components if len(c) < MIN_CLUSTER_SIZE))\n",
    "print(f\"\\nHex IDs to prune (cluster size < {MIN_CLUSTER_SIZE}): {len(small_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wy53wuz9dol",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T09:43:05.201607Z",
     "iopub.status.busy": "2026-02-28T09:43:05.201515Z",
     "iopub.status.idle": "2026-02-28T09:43:09.420951Z",
     "shell.execute_reply": "2026-02-28T09:43:09.420476Z"
    },
    "papermill": {
     "duration": 4.221196,
     "end_time": "2026-02-28T09:43:09.421606",
     "exception": false,
     "start_time": "2026-02-28T09:43:05.200410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexes.geojson: 8410 -> 8410 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta.json: 8420 -> 8420 entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_05m_00d-07d.pq: 1,028,496 -> 1,028,496 rows (0 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_05m_07d-14d.pq: 1,892,431 -> 1,892,431 rows (0 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_05m_07d-28d.pq: 3,407,859 -> 3,407,859 rows (0 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_10m_00d-07d.pq: 1,015,297 -> 1,015,297 rows (0 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_10m_07d-14d.pq: 1,861,171 -> 1,861,171 rows (0 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_10m_07d-28d.pq: 3,320,873 -> 3,320,873 rows (0 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_15m_00d-07d.pq: 985,539 -> 985,535 rows (4 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_15m_07d-14d.pq: 1,803,563 -> 1,803,558 rows (5 dropped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectivity_15m_07d-28d.pq: 3,215,520 -> 3,215,515 rows (5 dropped)\n"
     ]
    }
   ],
   "source": [
    "# Remove small-cluster hexes from hexes.geojson, meta.json, and parquets\n",
    "with open(OUT_DIR / \"hexes.geojson\") as f:\n",
    "    gj = json.load(f)\n",
    "before = len(gj[\"features\"])\n",
    "gj[\"features\"] = [f for f in gj[\"features\"] if f[\"properties\"][\"id\"] not in small_ids]\n",
    "with open(OUT_DIR / \"hexes.geojson\", \"w\") as f:\n",
    "    json.dump(gj, f)\n",
    "print(f\"hexes.geojson: {before} -> {len(gj['features'])} features\")\n",
    "\n",
    "with open(OUT_DIR / \"meta.json\") as f:\n",
    "    meta = json.load(f)\n",
    "ids_col = meta[\"id\"]\n",
    "bad_row_keys = {k for k, v in ids_col.items() if v in small_ids}\n",
    "before_meta = len(ids_col)\n",
    "meta = {col: {k: v for k, v in col_data.items() if k not in bad_row_keys}\n",
    "        for col, col_data in meta.items()}\n",
    "with open(OUT_DIR / \"meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f)\n",
    "print(f\"meta.json: {before_meta} -> {len(meta['id'])} entries\")\n",
    "\n",
    "for path in sorted(OUT_DIR.glob(\"connectivity_*.pq\")):\n",
    "    df = pd.read_parquet(path)\n",
    "    before_pq = len(df)\n",
    "    mask = df[\"end_id\"].astype(int).isin(small_ids) | df[\"start_id\"].isin(small_ids)\n",
    "    df = df[~mask]\n",
    "    df.to_parquet(path, index=False)\n",
    "    print(f\"{path.name}: {before_pq:,} -> {len(df):,} rows ({mask.sum()} dropped)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.678284,
   "end_time": "2026-02-28T09:43:09.638427",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/04_clean_outputs.ipynb",
   "output_path": "notebooks/04_clean_outputs.exec.ipynb",
   "parameters": {},
   "start_time": "2026-02-28T09:42:58.960143",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}