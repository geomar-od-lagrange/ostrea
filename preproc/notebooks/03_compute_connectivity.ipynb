{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Compute connectivity matrix (one file)\n",
    "\n",
    "Processes a single file (`05m_00-07days`) via OPeNDAP using stride-75 chunking.\n",
    "Computes normalized relative dilution factors:\n",
    "\n",
    "$$F = \\frac{\\text{obs\\_sum}}{N_{\\text{hex0\\_sum}} \\cdot DT_h \\cdot n_{\\text{months\\_years}}} \\cdot \\frac{wf_{\\text{hex0}}}{wf_{\\text{hex1}}}$$\n",
    "\n",
    "Produces `database/data/connectivity.pq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": "import json\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nfrom pathlib import Path\n\nBASE = (\n    \"https://data.geomar.de/thredds/dodsC/\"\n    \"20.500.12085/11cc2d8f-4039-49d3-aaab-04ce0fb23190/submission\"\n)\n\nESCAPE_HEX = b\"(0, 0, 0)\"\nOUT_DIR = Path(\"../../database/data\")\n\n# Single file for viability test\nDEPTH = \"05m\"\nTIME = \"00-07days\"\nDT_H = 168  # hours in window\nTIME_LABEL = \"00d-07d\"\nSTRIDE = 75  # hex0 rows per OPeNDAP request (~100 MB/chunk); ignored for local files\n\n# Set to local input_comp/ dir to use compressed local NC files instead of OPeNDAP\nLOCAL_INPUT = True\nLOCAL_INPUT_DIR = Path(\"../input_comp\")\n\n_TIME_TO_DAYS = {\"00-07days\": \"07\", \"07-14days\": \"14\", \"07-28days\": \"28\"}\n\ndef url(depth, time):\n    name = f\"040_connectivity_analysis_{depth}_{time}.nc\"\n    return f\"{BASE}/040_connectivity_analysis_{depth}/{name}\"\n\ndef local_path(depth, time):\n    days = _TIME_TO_DAYS[time]\n    return LOCAL_INPUT_DIR / f\"{depth}_ds_conn_{days}.nc\"\n\n# Load hex label → int ID mapping built in notebook 02\nwith open(OUT_DIR / \"hex_label_to_id.json\") as f:\n    label_to_id = json.load(f)  # keys are str like \"(-1, -19, 20)\"\n\nprint(f\"Loaded {len(label_to_id)} hex labels\")\nif LOCAL_INPUT:\n    p = local_path(DEPTH, TIME)\n    print(f\"Using local file: {p} (exists={p.exists()})\")\nelse:\n    print(f\"Using OPeNDAP: {url(DEPTH, TIME)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": "if LOCAL_INPUT:\n    ds = xr.open_dataset(local_path(DEPTH, TIME), engine=\"netcdf4\")\nelse:\n    ds = xr.open_dataset(url(DEPTH, TIME), engine=\"netcdf4\")\nprint(ds)\n\nn_hex0 = ds.sizes[\"hex0\"]\nn_hex1 = ds.sizes[\"hex1\"]\nn_months = ds.sizes[\"month\"]\nn_years = ds.sizes[\"year\"]\nn_months_years = n_months * n_years\nprint(f\"\\nhex0={n_hex0}, hex1={n_hex1}, month={n_months}, year={n_years}\")\nprint(f\"n_months_years={n_months_years}, STRIDE={STRIDE}, chunks={int(np.ceil(n_hex0/STRIDE))}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": "# Load per-hex metadata needed for normalization\nhex0_labels = ds[\"hex0\"].values          # byte strings (OPeNDAP) or str (local netCDF4)\nhex1_labels = ds[\"hex1\"].values\nwf_hex0 = ds[\"water_fraction_hex0\"].values   # shape (hex0,)\nwf_hex1 = ds[\"water_fraction_hex1\"].values   # shape (hex1,)\n\ndef _to_str(v):\n    return v.decode() if isinstance(v, bytes) else str(v)\n\n# Find escape hex index in hex1\nescape_mask_hex1 = np.array([_to_str(v) == _to_str(ESCAPE_HEX) for v in hex1_labels])\nprint(f\"Escape hex in hex1: {escape_mask_hex1.sum()} occurrence(s)\")\n\n# Encode hex labels as str for ID lookup\nhex0_str = np.array([_to_str(b) for b in hex0_labels])\nhex1_str = np.array([_to_str(b) for b in hex1_labels])\n\n# hex1 IDs for non-escape hexes\nvalid_hex1_mask = ~escape_mask_hex1\nhex1_ids = np.array([label_to_id.get(s, -1) for s in hex1_str])\nprint(f\"hex1 IDs: min={hex1_ids[valid_hex1_mask].min()}, max={hex1_ids[valid_hex1_mask].max()}, missing={(hex1_ids[valid_hex1_mask] == -1).sum()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": "import time as time_mod\n\nrecords = []  # list of DataFrames\n\nif LOCAL_INPUT:\n    # Load entire obs array at once — fast from local disk\n    print(\"Loading obs from local file ...\")\n    t0 = time_mod.time()\n    obs_all = ds[\"obs\"].values  # shape (month, year, hex0, hex1)\n    print(f\"  loaded in {time_mod.time()-t0:.1f}s, shape={obs_all.shape}\")\n    obs_sum_all = np.nansum(obs_all, axis=(0, 1))  # (hex0, hex1)\n    N_hex0_sum_all = obs_sum_all.sum(axis=1)       # (hex0,)\n\n    for global_i in range(n_hex0):\n        if global_i % 1000 == 0:\n            print(f\"  {global_i}/{n_hex0} hex0 ...\")\n        if N_hex0_sum_all[global_i] == 0:\n            continue\n        src_label = hex0_str[global_i]\n        src_id = label_to_id.get(src_label, -1)\n        if src_id == -1:\n            continue\n        wf0 = wf_hex0[global_i]\n        if wf0 == 0 or np.isnan(wf0):\n            continue\n        row = obs_sum_all[global_i]\n        target_mask = valid_hex1_mask & (row > 0)\n        if target_mask.sum() == 0:\n            continue\n        tgt_ids = hex1_ids[target_mask]\n        tgt_obs = row[target_mask]\n        tgt_wf1 = wf_hex1[target_mask]\n        F_raw = (tgt_obs / (N_hex0_sum_all[global_i] * DT_H * n_months_years)) * (wf0 / tgt_wf1)\n        exp = np.floor(np.log10(F_raw))\n        F = np.round(F_raw * 10 ** (5 - exp)) / 10 ** (5 - exp)\n        records.append(pd.DataFrame({\n            \"start_id\": np.int64(src_id),\n            \"end_id\": tgt_ids.astype(str),\n            \"weight\": F,\n        }))\nelse:\n    # OPeNDAP: process in stride-75 hex0 chunks\n    n_chunks = int(np.ceil(n_hex0 / STRIDE))\n    for chunk_idx in range(n_chunks):\n        i0 = chunk_idx * STRIDE\n        i1 = min(i0 + STRIDE, n_hex0)\n        if chunk_idx % 10 == 0:\n            print(f\"  chunk {chunk_idx}/{n_chunks} ...\")\n        obs_chunk = ds[\"obs\"].isel(hex0=slice(i0, i1)).values\n        obs_sum = np.nansum(obs_chunk, axis=(0, 1))\n        N_hex0_sum = obs_sum.sum(axis=1)\n        for local_i in range(i1 - i0):\n            global_i = i0 + local_i\n            if N_hex0_sum[local_i] == 0:\n                continue\n            src_label = hex0_str[global_i]\n            src_id = label_to_id.get(src_label, -1)\n            if src_id == -1:\n                continue\n            wf0 = wf_hex0[global_i]\n            if wf0 == 0 or np.isnan(wf0):\n                continue\n            row = obs_sum[local_i]\n            target_mask = valid_hex1_mask & (row > 0)\n            if target_mask.sum() == 0:\n                continue\n            tgt_ids = hex1_ids[target_mask]\n            tgt_obs = row[target_mask]\n            tgt_wf1 = wf_hex1[target_mask]\n            F_raw = (tgt_obs / (N_hex0_sum[local_i] * DT_H * n_months_years)) * (wf0 / tgt_wf1)\n            exp = np.floor(np.log10(F_raw))\n            F = np.round(F_raw * 10 ** (5 - exp)) / 10 ** (5 - exp)\n            records.append(pd.DataFrame({\n                \"start_id\": np.int64(src_id),\n                \"end_id\": tgt_ids.astype(str),\n                \"weight\": F,\n            }))\n\nds.close()\nprint(f\"\\nDone. {len(records)} source hex blocks.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate and tag\n",
    "conn = pd.concat(records, ignore_index=True)\n",
    "conn[\"depth\"] = DEPTH\n",
    "conn[\"time\"] = TIME_LABEL\n",
    "\n",
    "# Reorder columns to match schema\n",
    "conn = conn[[\"start_id\", \"end_id\", \"time\", \"depth\", \"weight\"]]\n",
    "\n",
    "print(conn.dtypes)\n",
    "print(f\"\\nRows: {len(conn):,}\")\n",
    "print(f\"weight range: {conn.weight.min():.3e} – {conn.weight.max():.3e}\")\n",
    "print(conn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": "out_path = OUT_DIR / f\"connectivity_{DEPTH}_{TIME_LABEL}.pq\"\nconn.to_parquet(out_path, index=False)\nprint(f\"Written: {out_path} ({out_path.stat().st_size / 1e6:.1f} MB, {len(conn):,} rows)\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}